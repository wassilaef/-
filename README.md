# retardavion
PrÃ©diction du retard mensuel moyen des vols
ChaÃ®ne complÃ¨te Kedro + MLflow : depuis le nettoyage des donnÃ©es jusquâ€™au versioning du modÃ¨le.


#CrÃ©er et activer lâ€™environnement
python3 -m venv venv
source venv/bin/activate
Installer les dÃ©pendances
pip install -r requirements.txt
âš™ï¸ Configuration

Catalog (conf/base/catalog.yml)
DÃ©clare les jeux de donnÃ©esâ€¯:
primary:
  type: pandas.CSVDataSet
  filepath: data/03_primary/primary.csv
X_train:
  type: pandas.CSVDataSet
  filepath: data/06_models/X_train.csv
# â€¦ et X_test, y_train, y_test
ParamÃ¨tres (conf/base/parameters.yml)
test_ratio: 0.2
target_column: "Retard mensuel moyen Ã  l'arrivÃ©e des vols exploitÃ©s par la Cie sur la relation (min)"

# MLflow
automl_max_evals: 100
log_to_mlflow: true
experiment_id: "retard_avion_experiment"
mlflow_server_uri: "http://127.0.0.1:5000"
ğŸ”„ Pipelines Kedro

1. Data Processing
Nettoyage, encodage, split train/test.
kedro run --pipeline data_processing
preprocess_data â†’ data/03_primary/primary.csv â†’ DataFrame nettoyÃ©
encode_features â†’ encode toutes les colonnes object
split_dataset â†’ gÃ©nÃ¨re X_train.csv, X_test.csv, y_train.csv, y_test.csv
2. Data Training
Recherche dâ€™hyperâ€‘paramÃ¨tres, entraÃ®nement final, log vers MLflow + Model Registry.
kedro run --pipeline data_training
optimize_hyp (Hyperopt + RepeatedKFold) â†’ meilleurs params
train_model â†’ entraÃ®nement LGBMRegressor
auto_ml
configure MLflow
logâ€¯: hyperâ€‘params, RMSE train/test, baseline
log modÃ¨le et lâ€™enregistre dans le Model Registry (retard_avion_model)
ğŸ“Š MLflow

Lancer le serveur
mlflow ui --host 127.0.0.1 --port 5000
Explorer
Experimentsâ€¯: â€œretard_avion_experimentâ€ â†’ mÃ©triques, hyperâ€‘params, artefacts
Model Registryâ€¯: versionner, promouvoir (Staging, Production)
ğŸ§ª Tests Ã  venir

Tests prÃ©â€‘entraÃ®nementâ€¯: cohÃ©rence de donnÃ©es, proportions, taille minimaleâ€¦
Tests postâ€‘entraÃ®nementâ€¯: comportement du modÃ¨le vs baseline, cas dâ€™usage.
ğŸ“ˆ RÃ©sultats & Observations

RMSE train vs test comparÃ© Ã  une baseline (prÃ©diction de la moyenne)
Sur- et sousâ€‘apprentissage observÃ©s via diffÃ©rence RMSE train/test
ğŸ”œ Prochaines Ã©tapes

Mettre en place les tests (pytest + kedro-test)
DÃ©ployer la version production du modÃ¨le (API FastAPI, Docker)
Surveiller en production (drift, alertes, rÃ©â€‘entraÃ®nement automatique)
